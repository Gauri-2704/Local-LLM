{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd133ab0",
   "metadata": {},
   "source": [
    "# Run a simple training loop on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import local_llm as lllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623fd101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1 SETUP\n",
    "assets_dir = lllm.setup_bert_base(\n",
    "    checkpoints=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/uncased_L-12_H-768_A-12\",\n",
    "    vocab=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/uncased_L-12_H-768_A-12/vocab.txt\",\n",
    "    config=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/uncased_L-12_H-768_A-12/bert_config.json\",\n",
    "    # optional; by default this would become ..\\assets\\bert-base-local\n",
    "    output_dir=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local1\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Now assets_dir should contain:\n",
    "#   pytorch_model.bin\n",
    "#   config.json\n",
    "#   vocab.txt\n",
    "\n",
    "\n",
    "# # OPTION 2 SETUP\n",
    "# assets_dir = lllm.setup_bert_base(\n",
    "#     model_params=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local/pytorch_model.bin\",\n",
    "#     vocab=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local/vocab.txt\",\n",
    "#     config=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local/config.json\",\n",
    "#     # output_dir optional; if omitted, uses the folder containing model_params\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd1a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build tokenizer\n",
    "encoder = lllm.build_bert_input_encoder(assets_dir, max_len=256, lowercase=True)\n",
    "\n",
    "texts = [\"This is a test.\", \"Another example.\"]\n",
    "encoded = [encoder.encode(t) for t in texts]\n",
    "\n",
    "input_ids = torch.tensor([e.input_ids for e in encoded])\n",
    "attention_mask = torch.tensor([e.attention_mask for e in encoded])\n",
    "token_type_ids = torch.tensor([e.token_type_ids for e in encoded])\n",
    "print(f\"input_ids:{input_ids}\")\n",
    "print(f\"attention_mask:{attention_mask}\")\n",
    "print(f\"token_type_ids:{token_type_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load BERT + classifier head\n",
    "num_labels = 8\n",
    "model = lllm.BertTextClassifier.from_pretrained(assets_dir, num_labels=num_labels, pooling=\"cls\")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70437576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Simple training step\n",
    "labels = torch.randint(0, num_labels, (input_ids.size(0),))\n",
    "out = model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    token_type_ids=token_type_ids,\n",
    "    labels=labels,\n",
    ")\n",
    "loss = out[\"loss\"]\n",
    "loss.backward()\n",
    "# optimizer.step(), optimizer.zero_grad(), etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d292df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inference\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids,\n",
    "    )[\"logits\"]\n",
    "    preds = logits.argmax(dim=-1)\n",
    "\n",
    "print(preds)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
